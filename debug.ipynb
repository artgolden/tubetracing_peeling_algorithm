{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 298, 621)\n",
      "[ 1 22 46]\n"
     ]
    }
   ],
   "source": [
    "# script_hang indefinitely at points_to_convex_hull_volume_mask\n",
    "\n",
    "import numpy as np\n",
    "import stackview\n",
    "from vedo import Points, ConvexHull, Volume\n",
    "\n",
    "\n",
    "def points_to_convex_hull_volume_mask(points, volume_shape_zyx, dilation_radius=3) -> Volume:\n",
    "    \"\"\"\n",
    "    Converts a set of 3D points to a binary volume mask of the inner part of the embryo using a convex hull.\n",
    "\n",
    "    This function takes a set of 3D points and a volume shape, constructs a convex hull from the points,\n",
    "    binarizes the convex hull into a volume mask, and then erodes/dilates the mask. \n",
    "\n",
    "    Args:\n",
    "        points (numpy.ndarray): A numpy array of shape (N, 3) representing the 3D points in ZYX order.\n",
    "        volume_shape_zyx (tuple): A tuple (z, y, x) representing the shape of the volume.\n",
    "        dilation_radius (int): The radius of the dilation applied to the volume mask.  This expands the mask\n",
    "            outwards, useful for ensuring complete coverage of the structure represented by the points.\n",
    "\n",
    "    Returns:\n",
    "        vedo.Volume: A vedo.Volume object representing the binary volume mask.  The mask has values of 255 inside\n",
    "            the convex hull and 0 outside.\n",
    "    \"\"\"\n",
    "    points_raw = points[:, [2, 1, 0]]\n",
    "    pts = Points(points_raw)\n",
    "    print(\"Creating convex hull from points\")\n",
    "    hull = ConvexHull(pts)\n",
    "\n",
    "    vol_shape_xyz = volume_shape_zyx[::-1]\n",
    "    print(\"Binarizing convex hull into volume mask\")\n",
    "    vol_mask = hull.binarize(values=(255,0),dims=vol_shape_xyz,spacing=[1,1,1], origin=(0,0,0))\n",
    "    if dilation_radius > 0:\n",
    "        print(f\"Dilating with radius of {dilation_radius}\")\n",
    "        modified = vol_mask.clone().dilate(neighbours=(dilation_radius,dilation_radius,dilation_radius))\n",
    "    else:\n",
    "        erosion_radius = abs(dilation_radius)\n",
    "        print(f\"Eroding with erosion radius of {erosion_radius}\")\n",
    "        modified = vol_mask.clone().erode(neighbours=(erosion_radius,erosion_radius,erosion_radius))\n",
    "    return modified\n",
    "\n",
    "down_cropped = np.load(\"/scratch/artemiy/test_data_for_serosa_peeling/peeling_debug/script_hang_at__points_to_convex_hull_volume_mask/down_cropped_tp_767.npy\")\n",
    "print(down_cropped.shape)\n",
    "points = np.load(\"/scratch/artemiy/test_data_for_serosa_peeling/peeling_debug/script_hang_at__points_to_convex_hull_volume_mask/tp_767_surface_points.npy\") \n",
    "print(points[0,:,:])\n",
    "# mod = points_to_convex_hull_volume_mask(points, volume_shape_zyx=down_cropped.shape, dilation_radius=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae778030cd76452daa1ae1b55805d8e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(VBox(children=(HBox(children=(VBox(children=(ImageWidget(height=298, width=621),…"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackview.slice(down_cropped, continuous_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wbns import substract_background\n",
    "\n",
    "only_structures = substract_background(down_cropped, 4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f30e90b6b5334f388b3dbf4f489c6e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(VBox(children=(HBox(children=(VBox(children=(ImageWidget(height=298, width=621),…"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackview.slice(only_structures, continuous_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542a095a3bd248f38b8363acf5912cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(VBox(children=(HBox(children=(VBox(children=(ImageWidget(height=298, width=621),…"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Otsu is clearly failing hard, and whole image is 1 value\n",
    "\n",
    "from skimage import filters\n",
    "from scipy import ndimage as cpu_ndimage\n",
    "\n",
    "\n",
    "substracted_bkg = only_structures\n",
    "th = filters.threshold_otsu(substracted_bkg)\n",
    "mask = substracted_bkg >= th\n",
    "\n",
    "structuring_element = np.ones((3,3,3))\n",
    "eroded_mask = cpu_ndimage.binary_erosion(mask, structure=structuring_element).astype(mask.dtype)  # Keep original datatype\n",
    "# Zerroing out the border to remove artifacts that wbns generates\n",
    "zero_y = int(eroded_mask.shape[1] * (1.15 - 1) / 2) \n",
    "zero_x = int(eroded_mask.shape[2] * (1.15 - 1) / 2)\n",
    "eroded_mask[:,-zero_y:,:] = False\n",
    "eroded_mask[:,:zero_y,:] = False\n",
    "eroded_mask[:,:,-zero_x:] = False\n",
    "eroded_mask[:,:,:zero_x] = False\n",
    "stackview.slice(mask, continuous_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b1d07d92d945578ee658aa10b8e6ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(VBox(children=(HBox(children=(VBox(children=(ImageWidget(height=298, width=621),…"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substracted_bkg = only_structures\n",
    "th = filters.threshold_mean(substracted_bkg)\n",
    "mask = substracted_bkg >= th\n",
    "stackview.slice(mask, continuous_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23110952, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92905, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "points_766 = np.load(\"/scratch/artemiy/test_data_for_serosa_peeling/peeling_debug/script_hang_at__points_to_convex_hull_volume_mask/tp_766_surface_points.npy\")\n",
    "points_766.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function execution time: 3.1477 seconds\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import ConvexHull\n",
    "import time \n",
    "\n",
    "start_time = time.perf_counter()\n",
    "hull = ConvexHull(points)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Function execution time: {execution_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruning points in a surface mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def prune_slice_cpu(slice_2d, radius=4):\n",
    "    \"\"\"\n",
    "    Prune a 2D boolean slice so that within each circular neighborhood of radius `radius`\n",
    "    only the True pixel that is furthest from the mid_point is retained.\n",
    "\n",
    "    Parameters:\n",
    "      slice_2d : 2D numpy array (bool)\n",
    "          Input slice.\n",
    "      radius : int, optional\n",
    "          Radius of the circular neighborhood (default is 4).\n",
    "\n",
    "    Returns:\n",
    "      pruned : 2D numpy array (bool)\n",
    "          The pruned slice.\n",
    "    \"\"\"\n",
    "    H, W = slice_2d.shape\n",
    "    # Define the mid_point as the right middle pixel (row=H//2, col=W-1)\n",
    "    mid_point = (H // 2, W - 1)\n",
    "    \n",
    "    # Find all indices where the pixel is True\n",
    "    true_indices = np.argwhere(slice_2d)\n",
    "    if len(true_indices) == 0:\n",
    "        return slice_2d.copy()\n",
    "    \n",
    "    # Compute squared Euclidean distances from each true pixel to the mid_point.\n",
    "    distances = (true_indices[:, 0] - mid_point[0])**2 + (true_indices[:, 1] - mid_point[1])**2\n",
    "    \n",
    "    # Process pixels in order of descending distance (furthest first)\n",
    "    order = np.argsort(-distances)\n",
    "    sorted_indices = true_indices[order]\n",
    "    \n",
    "    # Create an output array and a suppression mask (both same shape as slice_2d)\n",
    "    pruned = np.zeros_like(slice_2d, dtype=bool)\n",
    "    suppressed = np.zeros_like(slice_2d, dtype=bool)\n",
    "    \n",
    "    # Precompute offsets for a disk-shaped footprint (all offsets (dy,dx) such that distance<=radius)\n",
    "    offsets = []\n",
    "    for dy in range(-radius, radius + 1):\n",
    "        for dx in range(-radius, radius + 1):\n",
    "            if np.sqrt(dy**2 + dx**2) <= radius:\n",
    "                offsets.append((dy, dx))\n",
    "    \n",
    "    # Greedy suppression: for each candidate pixel, if it has not been suppressed,\n",
    "    # mark it as kept and then suppress all pixels in its neighborhood.\n",
    "    for r, c in sorted_indices:\n",
    "        if suppressed[r, c]:\n",
    "            continue\n",
    "        pruned[r, c] = True\n",
    "        # Suppress all pixels in the disk neighborhood around (r, c)\n",
    "        for dy, dx in offsets:\n",
    "            rr = r + dy\n",
    "            cc = c + dx\n",
    "            if 0 <= rr < H and 0 <= cc < W:\n",
    "                suppressed[rr, cc] = True\n",
    "                \n",
    "    return pruned\n",
    "\n",
    "def prune_volume_cpu(volume, radius=4, num_processes=None):\n",
    "    \"\"\"\n",
    "    Prune a 3D boolean volume along the first axis using CPU multiprocessing.\n",
    "    Each 2D slice is pruned independently.\n",
    "\n",
    "    Parameters:\n",
    "      volume : 3D numpy array (bool)\n",
    "          Input volume with shape (slices, height, width).\n",
    "      radius : int, optional\n",
    "          Radius for the neighborhood (default is 4).\n",
    "      num_processes : int, optional\n",
    "          Number of processes to use (defaults to the number of CPU cores).\n",
    "\n",
    "    Returns:\n",
    "      pruned_volume : 3D numpy array (bool)\n",
    "          The volume after pruning.\n",
    "    \"\"\"\n",
    "    slices = [volume[i] for i in range(volume.shape[0])]\n",
    "    with Pool(processes=num_processes) as pool:\n",
    "        results = pool.starmap(prune_slice_cpu, [(s, radius) for s in slices])\n",
    "    return np.stack(results, axis=0)\n",
    "\n",
    "def prune_slice_gpu(slice_2d, radius=4):\n",
    "    \"\"\"\n",
    "    GPU-accelerated pruning for a single 2D slice using CuPy.\n",
    "    This implementation computes a score for each pixel (its squared distance from mid_point)\n",
    "    and uses a maximum filter with a disk-shaped footprint to approximate non-maximum suppression.\n",
    "    Note: In regions with tied maximum scores, more than one pixel may be retained.\n",
    "\n",
    "    Parameters:\n",
    "      slice_2d : 2D numpy array (bool)\n",
    "          Input slice.\n",
    "      radius : int, optional\n",
    "          Radius for the neighborhood (default is 4).\n",
    "\n",
    "    Returns:\n",
    "      pruned : 2D numpy array (bool)\n",
    "          The pruned slice (transferred back to CPU memory).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import cupy as cp\n",
    "        import cupyx.scipy.ndimage as cndi\n",
    "    except ImportError:\n",
    "        raise ImportError(\"CuPy is not installed. Install CuPy to use GPU acceleration.\")\n",
    "    \n",
    "    H, W = slice_2d.shape\n",
    "    mid_point = (H // 2, W - 1)\n",
    "    \n",
    "    # Transfer the slice to the GPU\n",
    "    slice_gpu = cp.array(slice_2d)\n",
    "    # Create coordinate grids\n",
    "    y, x = cp.indices(slice_gpu.shape)\n",
    "    # Compute the score: for true pixels, use squared distance from mid_point; for false, set to -inf\n",
    "    score = cp.where(slice_gpu, (y - mid_point[0])**2 + (x - mid_point[1])**2, -cp.inf)\n",
    "    \n",
    "    # Create a disk-shaped footprint\n",
    "    y_off, x_off = cp.meshgrid(cp.arange(-radius, radius + 1), cp.arange(-radius, radius + 1), indexing='ij')\n",
    "    footprint = cp.sqrt(y_off**2 + x_off**2) <= radius\n",
    "    \n",
    "    # Apply a maximum filter using the disk footprint\n",
    "    local_max = cndi.maximum_filter(score, footprint=footprint)\n",
    "    \n",
    "    # Identify local maxima (approximate non-maximum suppression)\n",
    "    local_maxima = (score == local_max) & (score != -cp.inf)\n",
    "    \n",
    "    # Transfer the result back to the CPU\n",
    "    pruned = cp.asnumpy(local_maxima)\n",
    "    return pruned\n",
    "\n",
    "def prune_volume_gpu(volume, radius=4):\n",
    "    \"\"\"\n",
    "    Prune a 3D boolean volume using GPU acceleration.\n",
    "    Each 2D slice (along the first axis) is processed on the GPU.\n",
    "\n",
    "    Parameters:\n",
    "      volume : 3D numpy array (bool)\n",
    "          Input volume with shape (slices, height, width).\n",
    "      radius : int, optional\n",
    "          Radius for the neighborhood (default is 4).\n",
    "\n",
    "    Returns:\n",
    "      pruned_volume : 3D numpy array (bool)\n",
    "          The pruned volume.\n",
    "    \"\"\"\n",
    "    pruned_slices = []\n",
    "    for i in range(volume.shape[0]):\n",
    "        pruned_slice = prune_slice_gpu(volume[i], radius)\n",
    "        pruned_slices.append(pruned_slice)\n",
    "    return np.stack(pruned_slices, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artemiy/mambaforge/envs/tubetracing/lib/python3.10/site-packages/stackview/_static_view.py:101: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
      "  h, _ = np.histogram(self.obj, bins=num_bins)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<img src=\"data:image/png;base64,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\"></img>\n",
       "</td>\n",
       "<td style=\"text-align: center; vertical-align: top;\">\n",
       "\n",
       "<table>\n",
       "<tr><td>shape</td><td>(290,&nbsp;170)</td></tr>\n",
       "<tr><td>dtype</td><td>bool</td></tr>\n",
       "<tr><td>size</td><td>48.1 kB</td></tr>\n",
       "<tr><td>min</td><td>False</td></tr><tr><td>max</td><td>True</td></tr>\n",
       "</table>\n",
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAALQAAAB4CAYAAABb59j9AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAAj9JREFUeJzt10Gq01AYgNHb4jRdQGnABbgPB27ImThzQw7chwsQ+sgCWhCcNA7kPRBFhL7w4OOcUULCf+/gI9zs1nVdB0TsX3oD8JwETYqgSRE0KYImRdCkCJoUQZMiaFIETYqgSRE0Ka+2Gny73cayLGOaprHb7bZahoB1Xcf1eh3H43Hs9/d9YzcLelmWMc/zVuMJOp/P43Q63TVjs6CnaRpj/Nrk4XDYahkCLpfLmOf5qZl7bBb04zHjcDgImv/yHEdTP4WkCJqUzY4c//L6/een62+f3r3EFojyhSZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNyqutBq/rOsYY43K5/PHs9uP70/XfntPx5sOX3+6/fnz7xzuPDTw2c4/d+hxT/uLh4WHM87zFaKLO5/M4nU53zdgs6NvtNpZlGdM0jd1ut8USRKzrOq7X6zgej2O/v+8UvFnQ8BL8FJIiaFIETYqgSRE0KYImRdCkCJoUQZMiaFJ+Aoi6UwBdFikxAAAAAElFTkSuQmCC\"></img>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "StackViewNDArray([[False, False, False, ..., False, False, False],\n",
       "                  [False, False, False, ..., False, False, False],\n",
       "                  [False, False, False, ..., False, False, False],\n",
       "                  ...,\n",
       "                  [False, False, False, ..., False, False, False],\n",
       "                  [False, False, False, ..., False, False, False],\n",
       "                  [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tifffile as tiff\n",
    "mask = tiff.imread(\"outs/tp_301_wbns_surface_voxels_true.tif\")\n",
    "mask = np.transpose(mask, (2,1,0))\n",
    "stackview.insight(mask[244])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original true pixel counts per slice:\n"
     ]
    },
    {
     "ename": "TypingError",
     "evalue": "\u001b[1mFailed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1m\u001b[1m\u001b[1mNo implementation of function Function(<function zeros_like at 0x7fbc8c32cdc0>) found for signature:\n \n >>> zeros_like(array(bool, 2d, C), dtype=Function(<class 'bool'>))\n \nThere are 2 candidate implementations:\n\u001b[1m     - Of which 2 did not match due to:\n     Overload in function 'ol_np_zeros_like': File: numba/np/arrayobj.py: Line 4495.\n       With argument(s): '(array(bool, 2d, C), dtype=Function(<class 'bool'>))':\u001b[0m\n\u001b[1m      Rejected as the implementation raised a specific error:\n        TypingError: Failed in nopython mode pipeline (step: nopython frontend)\n      \u001b[1m\u001b[1m\u001b[1m\u001b[1mNo implementation of function Function(<built-in function empty_like>) found for signature:\n       \n       >>> empty_like(array(bool, 2d, C), dtype=Function(<class 'bool'>))\n       \n      There are 2 candidate implementations:\n      \u001b[1m      - Of which 2 did not match due to:\n            Overload in function 'ol_np_empty_like': File: numba/np/arrayobj.py: Line 4440.\n              With argument(s): '(array(bool, 2d, C), dtype=Function(<class 'bool'>))':\u001b[0m\n      \u001b[1m       Rejected as the implementation raised a specific error:\n               TypingError: \u001b[1mCannot parse input types to function np.empty_like(array(bool, 2d, C), Function(<class 'bool'>))\u001b[0m\u001b[0m\n        raised from /home/artemiy/mambaforge/envs/tubetracing/lib/python3.10/site-packages/numba/np/arrayobj.py:4458\n      \u001b[0m\n      \u001b[0m\u001b[1mDuring: resolving callee type: Function(<built-in function empty_like>)\u001b[0m\n      \u001b[0m\u001b[1mDuring: typing of call at /home/artemiy/mambaforge/envs/tubetracing/lib/python3.10/site-packages/numba/np/arrayobj.py (4501)\n      \u001b[0m\n      \u001b[1m\n      File \"../../../mambaforge/envs/tubetracing/lib/python3.10/site-packages/numba/np/arrayobj.py\", line 4501:\u001b[0m\n      \u001b[1m    def impl(a, dtype=None):\n      \u001b[1m        arr = np.empty_like(a, dtype=dtype)\n      \u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\n      \n      \u001b[0m\u001b[1mDuring: Pass nopython_type_inference\u001b[0m\u001b[0m\n  raised from /home/artemiy/mambaforge/envs/tubetracing/lib/python3.10/site-packages/numba/core/typeinfer.py:1074\n\u001b[0m\n\u001b[0m\u001b[1mDuring: resolving callee type: Function(<function zeros_like at 0x7fbc8c32cdc0>)\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of call at /tmp/ipykernel_1703107/2616119661.py (38)\n\u001b[0m\n\u001b[1m\nFile \"../../../../../tmp/ipykernel_1703107/2616119661.py\", line 38:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n\n\u001b[0m\u001b[1mDuring: Pass nopython_type_inference\u001b[0m\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/artemiy/mambaforge/envs/tubetracing/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/artemiy/mambaforge/envs/tubetracing/lib/python3.10/multiprocessing/pool.py\", line 51, in starmapstar\n    return list(itertools.starmap(args[0], args[1]))\n  File \"/home/artemiy/mambaforge/envs/tubetracing/lib/python3.10/site-packages/numba/core/dispatcher.py\", line 424, in _compile_for_args\n    error_rewrite(e, 'typing')\n  File \"/home/artemiy/mambaforge/envs/tubetracing/lib/python3.10/site-packages/numba/core/dispatcher.py\", line 365, in error_rewrite\n    raise e.with_traceback(None)\nnumba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1m\u001b[1m\u001b[1mNo implementation of function Function(<function zeros_like at 0x7fbc8c32cdc0>) found for signature:\n \n >>> zeros_like(array(bool, 2d, C), dtype=Function(<class 'bool'>))\n \nThere are 2 candidate implementations:\n\u001b[1m     - Of which 2 did not match due to:\n     Overload in function 'ol_np_zeros_like': File: numba/np/arrayobj.py: Line 4495.\n       With argument(s): '(array(bool, 2d, C), dtype=Function(<class 'bool'>))':\u001b[0m\n\u001b[1m      Rejected as the implementation raised a specific error:\n        TypingError: Failed in nopython mode pipeline (step: nopython frontend)\n      \u001b[1m\u001b[1m\u001b[1m\u001b[1mNo implementation of function Function(<built-in function empty_like>) found for signature:\n       \n       >>> empty_like(array(bool, 2d, C), dtype=Function(<class 'bool'>))\n       \n      There are 2 candidate implementations:\n      \u001b[1m      - Of which 2 did not match due to:\n            Overload in function 'ol_np_empty_like': File: numba/np/arrayobj.py: Line 4440.\n              With argument(s): '(array(bool, 2d, C), dtype=Function(<class 'bool'>))':\u001b[0m\n      \u001b[1m       Rejected as the implementation raised a specific error:\n               TypingError: \u001b[1mCannot parse input types to function np.empty_like(array(bool, 2d, C), Function(<class 'bool'>))\u001b[0m\u001b[0m\n        raised from /home/artemiy/mambaforge/envs/tubetracing/lib/python3.10/site-packages/numba/np/arrayobj.py:4458\n      \u001b[0m\n      \u001b[0m\u001b[1mDuring: resolving callee type: Function(<built-in function empty_like>)\u001b[0m\n      \u001b[0m\u001b[1mDuring: typing of call at /home/artemiy/mambaforge/envs/tubetracing/lib/python3.10/site-packages/numba/np/arrayobj.py (4501)\n      \u001b[0m\n      \u001b[1m\n      File \"../../../mambaforge/envs/tubetracing/lib/python3.10/site-packages/numba/np/arrayobj.py\", line 4501:\u001b[0m\n      \u001b[1m    def impl(a, dtype=None):\n      \u001b[1m        arr = np.empty_like(a, dtype=dtype)\n      \u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\n      \n      \u001b[0m\u001b[1mDuring: Pass nopython_type_inference\u001b[0m\u001b[0m\n  raised from /home/artemiy/mambaforge/envs/tubetracing/lib/python3.10/site-packages/numba/core/typeinfer.py:1074\n\u001b[0m\n\u001b[0m\u001b[1mDuring: resolving callee type: Function(<function zeros_like at 0x7fbc8c32cdc0>)\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of call at /tmp/ipykernel_1703107/2616119661.py (38)\n\u001b[0m\n\u001b[1m\nFile \"../../../../../tmp/ipykernel_1703107/2616119661.py\", line 38:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n\n\u001b[0m\u001b[1mDuring: Pass nopython_type_inference\u001b[0m\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal true pixel counts per slice:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# for i in range(100,volume.shape[0]-100):\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#     print(f\" Slice {i}: {np.sum(volume[i])} true pixels\")\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m pruned_gpu \u001b[38;5;241m=\u001b[39m \u001b[43mprune_volume_cpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvolume\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[45], line 82\u001b[0m, in \u001b[0;36mprune_volume_cpu\u001b[0;34m(volume, radius, num_processes)\u001b[0m\n\u001b[1;32m     80\u001b[0m slices \u001b[38;5;241m=\u001b[39m [volume[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(volume\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])]\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(processes\u001b[38;5;241m=\u001b[39mnum_processes) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m---> 82\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprune_slice_cpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mslices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mstack(results, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/tubetracing/lib/python3.10/multiprocessing/pool.py:375\u001b[0m, in \u001b[0;36mPool.starmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    370\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/tubetracing/lib/python3.10/multiprocessing/pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[0;31mTypingError\u001b[0m: \u001b[1mFailed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1m\u001b[1m\u001b[1mNo implementation of function Function(<function zeros_like at 0x7fbc8c32cdc0>) found for signature:\n \n >>> zeros_like(array(bool, 2d, C), dtype=Function(<class 'bool'>))\n \nThere are 2 candidate implementations:\n\u001b[1m     - Of which 2 did not match due to:\n     Overload in function 'ol_np_zeros_like': File: numba/np/arrayobj.py: Line 4495.\n       With argument(s): '(array(bool, 2d, C), dtype=Function(<class 'bool'>))':\u001b[0m\n\u001b[1m      Rejected as the implementation raised a specific error:\n        TypingError: Failed in nopython mode pipeline (step: nopython frontend)\n      \u001b[1m\u001b[1m\u001b[1m\u001b[1mNo implementation of function Function(<built-in function empty_like>) found for signature:\n       \n       >>> empty_like(array(bool, 2d, C), dtype=Function(<class 'bool'>))\n       \n      There are 2 candidate implementations:\n      \u001b[1m      - Of which 2 did not match due to:\n            Overload in function 'ol_np_empty_like': File: numba/np/arrayobj.py: Line 4440.\n              With argument(s): '(array(bool, 2d, C), dtype=Function(<class 'bool'>))':\u001b[0m\n      \u001b[1m       Rejected as the implementation raised a specific error:\n               TypingError: \u001b[1mCannot parse input types to function np.empty_like(array(bool, 2d, C), Function(<class 'bool'>))\u001b[0m\u001b[0m\n        raised from /home/artemiy/mambaforge/envs/tubetracing/lib/python3.10/site-packages/numba/np/arrayobj.py:4458\n      \u001b[0m\n      \u001b[0m\u001b[1mDuring: resolving callee type: Function(<built-in function empty_like>)\u001b[0m\n      \u001b[0m\u001b[1mDuring: typing of call at /home/artemiy/mambaforge/envs/tubetracing/lib/python3.10/site-packages/numba/np/arrayobj.py (4501)\n      \u001b[0m\n      \u001b[1m\n      File \"../../../mambaforge/envs/tubetracing/lib/python3.10/site-packages/numba/np/arrayobj.py\", line 4501:\u001b[0m\n      \u001b[1m    def impl(a, dtype=None):\n      \u001b[1m        arr = np.empty_like(a, dtype=dtype)\n      \u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\n      \n      \u001b[0m\u001b[1mDuring: Pass nopython_type_inference\u001b[0m\u001b[0m\n  raised from /home/artemiy/mambaforge/envs/tubetracing/lib/python3.10/site-packages/numba/core/typeinfer.py:1074\n\u001b[0m\n\u001b[0m\u001b[1mDuring: resolving callee type: Function(<function zeros_like at 0x7fbc8c32cdc0>)\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of call at /tmp/ipykernel_1703107/2616119661.py (38)\n\u001b[0m\n\u001b[1m\nFile \"../../../../../tmp/ipykernel_1703107/2616119661.py\", line 38:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n\n\u001b[0m\u001b[1mDuring: Pass nopython_type_inference\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "# Create a random 3D volume with 10 slices of 100x100 pixels; true pixels are sparse.\n",
    "# volume = np.random.rand(100, 1000, 1000) > 0.98\n",
    "volume = mask\n",
    "print(\"Original true pixel counts per slice:\")\n",
    "# for i in range(100,volume.shape[0]-100):\n",
    "#     print(f\" Slice {i}: {np.sum(volume[i])} true pixels\")\n",
    "\n",
    "pruned_gpu = prune_volume_cpu(volume, radius=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artemiy/mambaforge/envs/tubetracing/lib/python3.10/site-packages/stackview/_static_view.py:101: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
      "  h, _ = np.histogram(self.obj, bins=num_bins)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<img src=\"data:image/png;base64,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\"></img>\n",
       "</td>\n",
       "<td style=\"text-align: center; vertical-align: top;\">\n",
       "\n",
       "<table>\n",
       "<tr><td>shape</td><td>(290,&nbsp;170)</td></tr>\n",
       "<tr><td>dtype</td><td>bool</td></tr>\n",
       "<tr><td>size</td><td>48.1 kB</td></tr>\n",
       "<tr><td>min</td><td>False</td></tr><tr><td>max</td><td>True</td></tr>\n",
       "</table>\n",
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAALQAAAB4CAYAAABb59j9AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAAjZJREFUeJzt1zFq3EAYgNHZxa12+8WC3CcXyhFS5jK5T8CgA6wgkGaVIthNggmshcmX9yqBxD9TfBKjw7Zt24CI43tvAN6SoEkRNCmCJkXQpAiaFEGTImhSBE2KoEkRNCmCJuVhr8G3220syzKmaRqHw2GvZQjYtm2s6zoul8s4Hu/7xu4W9LIsY57nvcYT9PT0NB4fH++asVvQ0zSNMX5t8nQ67bUMAdfrdczz/NLMPXYL+vmYcTqdBM1feYujqZ9CUgRNym5Hjtd8+PT15frb54/vsQWifKFJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBk/Kw1+Bt28YYY1yv19/u3X58f7n+033+L88NPDdzj92CXtd1jDHGPM+vPnf+stcO+Nes6zrO5/NdMw7bW7wWf3C73cayLGOapnE4HPZYgoht28a6ruNyuYzj8b5T8G5Bw3vwU0iKoEkRNCmCJkXQpAiaFEGTImhSBE2KoEn5CQXfTNyyDfPbAAAAAElFTkSuQmCC\"></img>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "StackViewNDArray([[False, False, False, ..., False, False, False],\n",
       "                  [False, False, False, ..., False, False, False],\n",
       "                  [False, False, False, ..., False, False, False],\n",
       "                  ...,\n",
       "                  [False, False, False, ..., False, False, False],\n",
       "                  [False, False, False, ..., False, False, False],\n",
       "                  [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackview.insight(pruned_gpu[244])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparce_p = np.transpose(np.where(pruned_gpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "hull = ConvexHull(sparce_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original volume:\n",
      "[[[0 0 0 0 0 0 0 1]\n",
      "  [1 0 0 0 0 1 0 0]\n",
      "  [0 1 0 1 1 0 0 0]\n",
      "  [0 0 0 1 0 0 0 0]\n",
      "  [0 0 0 0 0 0 1 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 1 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 1 0 1 0 1 0]\n",
      "  [1 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 1 0 0 0 0 0 0]\n",
      "  [0 0 1 0 0 0 0 1]\n",
      "  [0 0 0 0 0 1 0 1]\n",
      "  [0 0 1 0 1 0 1 0]\n",
      "  [0 0 1 0 0 0 0 0]]]\n",
      "Pruned volume:\n",
      "[[[0 0 0 0 0 0 0 1]\n",
      "  [1 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 1 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 1 0]\n",
      "  [1 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 1]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 1 0 0 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "\n",
    "def prune_volume(volume):\n",
    "    \"\"\"\n",
    "    GPU accelerated pruning of voxels in a 3D volume.\n",
    "    \n",
    "    For each slice of the volume (along the first axis), the function splits the slice into\n",
    "    non-overlapping 4x4 blocks. For each block, only one pixel with value True is kept:\n",
    "    the one that is furthest from the mid-point of the slice, where the mid-point is defined as\n",
    "    (x=width-1, y=height//2). All other True pixels in the block are set to False.\n",
    "    \n",
    "    Parameters:\n",
    "        volume (np.ndarray): 3D numpy array with boolean values, shape (n_slices, height, width)\n",
    "    \n",
    "    Returns:\n",
    "        pruned_volume (np.ndarray): 3D numpy array with pruned voxels.\n",
    "    \"\"\"\n",
    "    # Transfer the volume to GPU memory.\n",
    "    volume_cp = cp.asarray(volume)\n",
    "    n_slices, height, width = volume_cp.shape\n",
    "\n",
    "    # Define the block (tile) size.\n",
    "    block_h, block_w = 4, 4\n",
    "\n",
    "    # Determine how many blocks (non-overlapping) fit along each dimension.\n",
    "    grid_x = (width + block_w - 1) // block_w\n",
    "    grid_y = (height + block_h - 1) // block_h\n",
    "\n",
    "    # Define the mid-point for the slice: rightmost x and center y.\n",
    "    mid_y = height // 2\n",
    "    mid_x = width // 2\n",
    "\n",
    "    # CUDA kernel that processes a single 4x4 block.\n",
    "    # It first finds the true pixel with the maximum squared distance to the mid-point,\n",
    "    # then clears all other true pixels in that block.\n",
    "    kernel_code = r'''\n",
    "    extern \"C\" __global__\n",
    "    void prune_block(bool* slice, int height, int width, int block_h, int block_w, int mid_y, int mid_x) {\n",
    "        int block_idx_x = blockIdx.x;  // block index along width\n",
    "        int block_idx_y = blockIdx.y;  // block index along height\n",
    "        int start_y = block_idx_y * block_h;\n",
    "        int start_x = block_idx_x * block_w;\n",
    "    \n",
    "        float max_dist = -1.0f;\n",
    "        int max_r = -1, max_c = -1;\n",
    "        \n",
    "        // First pass: Identify the true pixel with the furthest distance from mid_point.\n",
    "        for (int i = 0; i < block_h; i++) {\n",
    "            int r = start_y + i;\n",
    "            if (r >= height) break;\n",
    "            for (int j = 0; j < block_w; j++) {\n",
    "                int c = start_x + j;\n",
    "                if (c >= width) break;\n",
    "                int index = r * width + c;\n",
    "                if (slice[index]) {\n",
    "                    int dx = c - mid_x;\n",
    "                    int dy = r - mid_y;\n",
    "                    float dist = (float)(dx * dx + dy * dy);\n",
    "                    if (dist > max_dist) {\n",
    "                        max_dist = dist;\n",
    "                        max_r = r;\n",
    "                        max_c = c;\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        // Second pass: Clear all true pixels except the one with maximum distance.\n",
    "        for (int i = 0; i < block_h; i++) {\n",
    "            int r = start_y + i;\n",
    "            if (r >= height) break;\n",
    "            for (int j = 0; j < block_w; j++) {\n",
    "                int c = start_x + j;\n",
    "                if (c >= width) break;\n",
    "                int index = r * width + c;\n",
    "                if (slice[index] && !(r == max_r && c == max_c)) {\n",
    "                    slice[index] = false;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    '''\n",
    "    # Compile the kernel.\n",
    "    module = cp.RawModule(code=kernel_code)\n",
    "    prune_block = module.get_function(\"prune_block\")\n",
    "\n",
    "    # Process each slice independently.\n",
    "    for s in range(n_slices):\n",
    "        slice_cp = volume_cp[s]\n",
    "        prune_block(\n",
    "            (grid_x, grid_y),  # grid dimensions: one thread per 4x4 block\n",
    "            (1, 1, 1),         # single-thread per block (the kernel uses loops)\n",
    "            (slice_cp, np.int32(height), np.int32(width),\n",
    "             np.int32(block_h), np.int32(block_w), np.int32(mid_y), np.int32(mid_x))\n",
    "        )\n",
    "\n",
    "    # Transfer the result back to CPU.\n",
    "    return cp.asnumpy(volume_cp)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Example usage: Create a random 3D volume and prune it.\n",
    "    # For demonstration, generate a small volume of shape (2, 8, 8)\n",
    "    np.random.seed(0)\n",
    "    # volume = mask\n",
    "    # volume = (np.random.rand(170, 290, 635) > 0.9)\n",
    "    volume = (np.random.rand(2, 8, 8) > 0.8)\n",
    "    print(\"Original volume:\")\n",
    "    print(volume.astype(int))\n",
    "    pruned = prune_volume(volume)\n",
    "    print(\"Pruned volume:\")\n",
    "    print(pruned.astype(int))\n",
    "    # stackview.insight(pruned[244])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('bool')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mask = np.transpose(mask, (2, 1, 0))\n",
    "mask.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f7f36613c74b62bfe2d6ecbb08a349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(VBox(children=(HBox(children=(VBox(children=(ImageWidget(height=580, width=1270)…"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackview.slice(mask, continuous_update=True, zoom_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdca0954c9ff48dfad7152b20b12b897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(VBox(children=(HBox(children=(VBox(children=(ImageWidget(height=580, width=1270)…"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackview.slice(pruned, continuous_update=True, zoom_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c27bf4d7504369b738b77baee66c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(VBox(children=(HBox(children=(VBox(children=(ImageWidget(height=580, width=1270)…"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackview.slice(volume, continuous_update=True, zoom_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98416\n",
      "27849\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(mask))\n",
    "print(np.sum(pruned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original volume:\n",
      "Pruned volume:\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import njit, prange\n",
    "\n",
    "@njit(parallel=True, cache=True)\n",
    "def prune_volume_cpu(volume, block_h=4, block_w=4):\n",
    "    \"\"\"\n",
    "    CPU accelerated pruning of voxels in a 3D volume using Numba.\n",
    "    \n",
    "    For each slice in the 3D boolean volume (shape: [n_slices, height, width]), the function:\n",
    "      - Computes the mid-point of the slice as (x=width//2, y=height//2).\n",
    "      - Splits the slice into non-overlapping 4x4 blocks by default.\n",
    "      - Within each block, finds the True pixel furthest from the mid-point (using squared Euclidean distance).\n",
    "      - Prunes the block by setting all True pixels to False except the selected one.\n",
    "    \n",
    "    Parameters:\n",
    "        volume (np.ndarray): 3D numpy array with boolean values.\n",
    "        block_h (int): Height of each block.\n",
    "        block_w (int): Width of each block.\n",
    "        \n",
    "    Returns:\n",
    "        volume (np.ndarray): The modified volume with pruned voxels.\n",
    "    \"\"\"\n",
    "    n_slices, height, width = volume.shape\n",
    "    block_h, block_w = 4, 4\n",
    "    # mid-point for each slice (same for all slices)\n",
    "    mid_y = height // 2\n",
    "    mid_x = width // 2\n",
    "\n",
    "    # Compute the number of blocks along each dimension.\n",
    "    grid_y = (height + block_h - 1) // block_h\n",
    "    grid_x = (width + block_w - 1) // block_w\n",
    "\n",
    "    # Process each slice in parallel.\n",
    "    for s in prange(n_slices):\n",
    "        for by in range(grid_y):\n",
    "            for bx in range(grid_x):\n",
    "                start_y = by * block_h\n",
    "                start_x = bx * block_w\n",
    "                max_dist = -1.0\n",
    "                max_r = -1\n",
    "                max_c = -1\n",
    "                # First pass: Find the True pixel with the maximum distance.\n",
    "                for i in range(block_h):\n",
    "                    r = start_y + i\n",
    "                    if r >= height:\n",
    "                        break\n",
    "                    for j in range(block_w):\n",
    "                        c = start_x + j\n",
    "                        if c >= width:\n",
    "                            break\n",
    "                        if volume[s, r, c]:\n",
    "                            dx = c - mid_x\n",
    "                            dy = r - mid_y\n",
    "                            dist = dx * dx + dy * dy\n",
    "                            if dist > max_dist:\n",
    "                                max_dist = dist\n",
    "                                max_r = r\n",
    "                                max_c = c\n",
    "                # Second pass: Clear all True pixels except the one with max distance.\n",
    "                if max_r != -1:  # if at least one True pixel was found\n",
    "                    for i in range(block_h):\n",
    "                        r = start_y + i\n",
    "                        if r >= height:\n",
    "                            break\n",
    "                        for j in range(block_w):\n",
    "                            c = start_x + j\n",
    "                            if c >= width:\n",
    "                                break\n",
    "                            if volume[s, r, c] and not (r == max_r and c == max_c):\n",
    "                                volume[s, r, c] = False\n",
    "    return volume\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Example usage: create a small random volume of shape (2, 8, 8)\n",
    "    np.random.seed(0)\n",
    "    volume = (np.random.rand(170, 2900, 635) > 0.9)\n",
    "    print(\"Original volume:\")\n",
    "    # print(volume.astype(np.int32))\n",
    "    \n",
    "    # Create a copy if you wish to preserve the original volume.\n",
    "    # pruned = prune_volume_cpu(volume.copy())\n",
    "    print(\"Pruned volume:\")\n",
    "    # print(pruned.astype(np.int32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = (np.random.rand(170, 2900, 635) > 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned = prune_volume_cpu(mask.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0559a43302a24c80a9365a3e0b048cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(VBox(children=(HBox(children=(VBox(children=(ImageWidget(height=580, width=1270)…"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackview.slice(pruned, continuous_update=True, zoom_factor=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tubetracing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
